{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Predictive Modeling\n",
   "id": "a06cf889925d266f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "d885463da1cd2c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "final_dt = pd.read_csv(\"C:/Research/Msc/CMM709/CAUSALITY-EXPLORE/data/processed/medical_appointment_no_show_final.csv\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_dt",
   "id": "203f19ecf5ae3099",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_dt.info()",
   "id": "92f89aa9cace03aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.1 Split the Dataset",
   "id": "c1ff9d1dbe1c56dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define features (x) and target (y)\n",
    "x = final_dt.drop(columns=['no_show'])\n",
    "y = final_dt['no_show']\n",
    "\n",
    "# Convert categorical variables to numerical using one-hot encoding\n",
    "X = pd.get_dummies(x, drop_first=True)\n",
    "\n",
    "# Impute missing values with the mean (or median/mode)\n",
    "# impute = SimpleImputer(strategy='mean')\n",
    "# X = pd.DataFrame(impute.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ],
   "id": "f2eaf90576f4fd55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.2 Train and Evaluate Models\n",
    "<p>\n",
    "  Train and evaluate three models\n",
    "    <ol>\n",
    "       <li>Logistic Regression</li>\n",
    "       <li>Random Forest</li>\n",
    "       <li>XGBoost</li>\n",
    "    </ol>\n",
    "</p>"
   ],
   "id": "16aede62226b6c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ],
   "id": "3e5ff1c690322fe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Apply SMOTE to handle class imbalance\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "    # Evaluate to model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)  # ROC AUC score\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    graph_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    class_report = pd.DataFrame(graph_report).transpose()\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # Check the new class distribution\n",
    "    print(\"Class Imbalance handling SMOTE\\n\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(f\"Before SMOTE:\", Counter(y_train))\n",
    "    print(f\"After SMOTE:\", Counter(y_train_smote))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(\"----------------------\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    print(\"\\n\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"-----------------\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(class_report, annot=True, fmt='.2f', cmap='crest', cbar=False)\n",
    "    plt.title('Classification Report')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ],
   "id": "e927863e596ab3e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize models\n",
    "logistic_regression_model = LogisticRegression(random_state=42, max_iter=10000, class_weight='balanced')\n",
    "random_forest_classifier_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
    "XGBClassifier_model = XGBClassifier(n_estimators=200, random_state=42)"
   ],
   "id": "9aa43b08870b7caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate Logistic Regression",
   "id": "a585a9e890d68175"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Logistic Regression Results:\")\n",
    "print(\"----------------------------\")\n",
    "log_reg = evaluate_model(logistic_regression_model, X_train, y_train, X_test, y_test)"
   ],
   "id": "cfaa33bacef78484",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate Random Forest Classifier",
   "id": "fbfd4ab6870c95cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Evaluating Random Forest Model:\")\n",
    "print(\"-------------------------------\")\n",
    "rf_classifier = evaluate_model(random_forest_classifier_model, X_train, y_train, X_test, y_test)"
   ],
   "id": "2ad2fdabdb3fc119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate XGBoost Classifier",
   "id": "457964c1302fce34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"XGBoost Classifier Results:\")\n",
    "print(\"---------------------------\")\n",
    "xgboost_model = evaluate_model(XGBClassifier_model, X_train, y_train, X_test, y_test)"
   ],
   "id": "84a9e6e4d90bbafc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Improve Model Performance",
   "id": "97a1b6c646bdadb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop one-hot encoded neighbourhood columns to reduce dimensionality\n",
    "X_reduced =  final_dt.drop([col for col in final_dt.columns if col.startswith('neighbourhood_')], axis=1)\n",
    "\n",
    "# Resplit reduced data\n",
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(X_reduced, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set shape: {X_train_reduced.shape}\")\n",
    "print(f\"Test set shape: {X_test_reduced.shape}\")\n"
   ],
   "id": "a7e6244062119ac6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluate_model(logistic_regression_model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n",
    "evaluate_model(random_forest_classifier_model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)\n",
    "evaluate_model(XGBClassifier_model, X_train_reduced, y_train_reduced, X_test_reduced, y_test_reduced)"
   ],
   "id": "cce061b88d3336a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.4 Hyperparameter Tuning\n",
    "<p>\n",
    "\n",
    "Using `GridSearchCV` to tune `Hyperparameter` for the best-performing model, Random Forest\n",
    "\n",
    "</p>"
   ],
   "id": "8c4929f5d44ca215"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV",
   "id": "74f67fb2391b6181",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter grid for each model\n",
    "param_grid_log_reg_a = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],    # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],         # Regularization type\n",
    "    'solver': ['liblinear', 'saga']  # Solvers that support l1 penalty\n",
    "}\n",
    "\n",
    "param_grid_random_forest_a = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30], # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4]    # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "param_grid_xgb_a = {\n",
    "    'n_estimators': [50, 100, 200],       # Number of trees in the ensemble\n",
    "    'learning_rate': [0.01, 0.1, 0.2],    # Step size shrinkage used in update to prevent overfitting\n",
    "    'max_depth': [3, 5, 7],               # Maximum depth of a tree\n",
    "    'subsample': [0.8, 0.9, 1.0],         # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]   # Subsample ratio of columns when constructing each tree\n",
    "}"
   ],
   "id": "d7d3d4148d2d2085",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. GridSearchCV",
   "id": "70df756a174e31f7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Performance GridSearchCV for Logistic Regression\n",
    "print(\"Tuning Logistic Regression....\")\n",
    "grid_log_reg = GridSearchCV(logistic_regression_model, param_grid_log_reg_a, n_jobs=10, cv=5, scoring='accuracy', verbose=3)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Logistic Regression: {grid_log_reg.best_params_}\")\n",
    "print(f\"Best cross-validation score for Logistic Regression: {grid_log_reg.best_score_:.4f}\")"
   ],
   "id": "d2fbd3ad0a2bf2ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Performance GridSearchCV for Random Forest\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "grid_rf = GridSearchCV(random_forest_classifier_model, param_grid_random_forest_a, n_jobs=10, cv=5, scoring='accuracy', verbose=3)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Random Forest: {grid_rf.best_params_}\")\n",
    "print(f\"Best cross-validation score for Random Forest: {grid_rf.best_score_:.4f}\")"
   ],
   "id": "1ed5561b312f1be9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Performance GridSearchCV for XGBoost\n",
    "print(\"\\nTuning XGBoost...\")\n",
    "grid_xgb = GridSearchCV(XGBClassifier_model, param_grid_xgb_a, n_jobs=10, cv=5, scoring='accuracy', verbose=3)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(f\"Best parameters for XGBoost: {grid_xgb.best_params_}\")\n",
    "print(f\"Best cross-validation score for XGBoost: {grid_xgb.best_score_:.4f}\")"
   ],
   "id": "efd7b744107ec485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. RandomizedSearchCV",
   "id": "81d2fdc58005cb11"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for Logistic Regression\n",
    "print(\"\\nTuning Logistic Regression...\")\n",
    "random_log_reg = RandomizedSearchCV(logistic_regression_model, param_grid_log_reg_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_log_reg.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Logistic Regression:\", random_log_reg.best_params_)\n",
    "print(f\"Best cross-validation score for Logistic Regression:\", random_log_reg.best_score_)"
   ],
   "id": "460674e643091aca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for Random Forest\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "random_rf = RandomizedSearchCV(random_forest_classifier_model, param_grid_random_forest_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_rf.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Random Forest:\", random_rf.best_params_)\n",
    "print(f\"Best cross-validation score for Random Forest:\", random_rf.best_score_)"
   ],
   "id": "fc318446e2b90b28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for XGBoost\n",
    "print(\"\\nTuning XGBoost...\")\n",
    "random_xgb = RandomizedSearchCV(XGBClassifier_model, param_grid_xgb_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_xgb.fit(X_train, y_train)\n",
    "print(f\"Best parameters for XGBoost:\", random_xgb.best_params_)\n",
    "print(f\"Best cross-validation score for XGBoost:\", random_xgb.best_score_)"
   ],
   "id": "77caec97b4bf866a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. RandomizedSearchCV",
   "id": "fd4867f0d039cf44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for Logistic Regression\n",
    "print(\"\\nTuning Logistic Regression...\")\n",
    "random_log_reg = RandomizedSearchCV(logistic_regression_model, param_grid_log_reg_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_log_reg.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Logistic Regression:\", random_log_reg.best_params_)\n",
    "print(f\"Best cross-validation score for Logistic Regression:\", random_log_reg.best_score_)"
   ],
   "id": "76263e49ab6a9b59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for Random Forest\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "random_rf = RandomizedSearchCV(random_forest_classifier_model, param_grid_random_forest_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_rf.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Random Forest:\", random_rf.best_params_)\n",
    "print(f\"Best cross-validation score for Random Forest:\", random_rf.best_score_)"
   ],
   "id": "b9481caa65549601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform RandomizedSearchCV for XGBoost\n",
    "print(\"\\nTuning XGBoost...\")\n",
    "random_xgh = RandomizedSearchCV(XGBClassifier_model, param_grid_xgb_a, n_iter=10, cv=5, scoring='accuracy', verbose=3)\n",
    "random_xgh.fit(X_train, y_train)\n",
    "print(f\"Best parameters for XGBoost:\", random_xgh.best_params_)\n",
    "print(f\"Best cross-validation score for XGBoost:\", random_xgh.best_score_)"
   ],
   "id": "eced647dc6443d58",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
